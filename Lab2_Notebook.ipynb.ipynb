{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d2118eb3",
   "metadata": {},
   "source": [
    "## Step 1: Hello, Data!\n",
    "\n",
    "In this step, I load the raw sales transactions CSV file into a DataFrame and display the first three rows to understand the structure of the data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d00bd3c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- importing the pandas library ----------\n",
    "import pandas as pd\n",
    "\n",
    "# ---------- reading  CSV file ----------\n",
    "file1 = r\"D:\\Conestoga\\Machine Learning Programming\\Lab-2\\sales.csv\"\n",
    "data1 = pd.read_csv(file1)\n",
    "\n",
    "# ---------- displaying the first 3 rows of the data ----------\n",
    "print(data1.head(3))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14e567c5",
   "metadata": {},
   "source": [
    "## Step 2: Pick the Right Container\n",
    "\n",
    "A `dict` is simple but doesn’t group behavior with data and a `namedtuple` is cleaner than a dict,but no custom functions\n",
    "A `class` is best here  because it helps organize the data and lets me add my own methods like `clean()` and `total()`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5df16203",
   "metadata": {},
   "source": [
    "## Step 3: Transaction Class and OO structure \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0056fd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- creating a class to represent one transaction ----------\n",
    "\n",
    "class Transaction:\n",
    "    def __init__(self, row):\n",
    "        # ---------- saving each column into the object ----------\n",
    "        self.order_date = row[\"Order Date\"]\n",
    "        self.customer_id = row[\"Order ID\"]\n",
    "        self.product = row[\"Item Type\"]\n",
    "        self.price = row[\"Unit Price\"]\n",
    "        self.quantity = row[\"Units Sold\"]\n",
    "        self.coupon_code = row[\"coupon_code\"]\n",
    "        self.shipping_city = row[\"Country\"] \n",
    "\n",
    "# ---------- creating a list to store all transaction objects ----------\n",
    "transaction_list = []\n",
    "\n",
    "# ---------- going through each row and converting to a Transaction object ----------\n",
    "for index, row in data1.iterrows():\n",
    "    obj = Transaction(row)\n",
    "    transaction_list.append(obj)\n",
    "\n",
    "# ---------- printing the first transaction as a check ----------\n",
    "print(vars(transaction_list[0]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bdf28de",
   "metadata": {},
   "source": [
    "\n",
    "In this step i created a Python class to represent each row in the sales data.\n",
    "I used real column names like \"Order Date\", \"Item Type\", and \"coupon_code\" from the CSV.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e36d6d08",
   "metadata": {},
   "source": [
    "##  Step 4: Bulk Loader \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91a1f4bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- importing List for return type hint ----------\n",
    "from typing import List\n",
    "\n",
    "# ---------- function to load all transactions ----------\n",
    "\n",
    "def load_transactions(dataframe) -> List[Transaction]:\n",
    "    # ---------- list to hold transaction objects ----------\n",
    "    result = []\n",
    "\n",
    "    # ---------- loop  each row in the dataframe ----------\n",
    "    for index, row in dataframe.iterrows():\n",
    "        obj = Transaction(row)      \n",
    "        result.append(obj)          \n",
    "\n",
    "    return result\n",
    "\n",
    "# ---------- using the function to load data ----------\n",
    "transactions = load_transactions(data1)\n",
    "\n",
    "print(vars(transactions[0]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09b975c7",
   "metadata": {},
   "source": [
    "in this step i made a function called `load_transactions()` to turn each row of the data into a `Transaction` object.\n",
    "This function goes through the dataframe row by row and makes a list of all  transactions.\n",
    "It helps to keep the code clean and now i can just call this function anytime I want to load the data as objects.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a1b82de",
   "metadata": {},
   "source": [
    "##  Step 5: Quick Profiling \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "578363bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- getting min, mean, and max of unit price ----------\n",
    "\n",
    "min_price = data1[\"Unit Price\"].min()\n",
    "mean_price = data1[\"Unit Price\"].mean()\n",
    "max_price = data1[\"Unit Price\"].max()\n",
    "\n",
    "print(\"Min price:\", min_price)\n",
    "print(\"Mean price:\", mean_price)\n",
    "print(\"Max price:\", max_price)\n",
    "\n",
    "# ---------- getting the number of unique shipping cities ----------\n",
    "unique_cities = data1[\"Country\"].nunique()\n",
    "\n",
    "print(\"Number of unique shipping cities:\", unique_cities)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "273a513e",
   "metadata": {},
   "source": [
    "so calculated the minimum, average, and maximum values for the \"Unit Price\" column using the pandas functions `.min()`, `.mean()`,  `.max()` and also counted how many cities are in the data. It showed 360, but this is wrong.\n",
    "\n",
    "Some city names are written in different ways, like \"canada\" and \"CANADA\", so they are counted more than onceI will fix this in the next steps.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "955ef2da",
   "metadata": {},
   "source": [
    "##  Step 6: Spot the Grime  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d370277e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ---------- Missing values ----------\n",
    "print(\"Missing values in each column:\")\n",
    "print(data1.isnull().sum())\n",
    "\n",
    "# ---------- Duplicate rows ----------\n",
    "print(\"Number of duplicate rows:\")\n",
    "print(data1.duplicated().sum())\n",
    "\n",
    "# ----------  Negative prices ----------\n",
    "print(\"Negative Unit Prices:\")\n",
    "print((data1[\"Unit Price\"] < 0).sum())\n",
    "\n",
    "# ----------  Zero or negative quantities ----------\n",
    "print(\"Zero or negative Units Sold:\")\n",
    "print((data1[\"Units Sold\"] <= 0).sum())\n",
    "\n",
    "# ----------  Country names not standardized ----------\n",
    "print(\"Different countries before cleaning:\")\n",
    "print(data1[\"Country\"].nunique())\n",
    "\n",
    "# ---------- check how many unique countries after standardizing----------\n",
    "fixed_countries = data1[\"Country\"].str.strip().str.lower()\n",
    "print(\"Different countries after cleaning:\")\n",
    "print(fixed_countries.nunique())\n",
    "\n",
    "# ----------   check date columns ----------\n",
    "data1[\"Order Date\"] = pd.to_datetime(data1[\"Order Date\"], errors='coerce', dayfirst=True)\n",
    "\n",
    "print(\"Bad Order Dates:\", data1[\"Order Date\"].isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab2d2862",
   "metadata": {},
   "source": [
    "## Spot the Grime  \n",
    "country  names have issues  \n",
    "1. they have extra spaces \n",
    "2. different cases. \n",
    "3. Dates were not in the same format.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee9211be",
   "metadata": {},
   "source": [
    "##  Step 7: Cleaning Rules \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e15dfe21",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ------------------to Convert Order Date -------------------- \n",
    "data1[\"Order Date\"] = pd.to_datetime(data1[\"Order Date\"], errors=\"coerce\", dayfirst=True)\n",
    "\n",
    "# ----------  Transaction class with clean() ----------\n",
    "class Transaction:\n",
    "    def __init__(self, row):\n",
    "        self.order_date = row[\"Order Date\"]\n",
    "        self.customer_id = row[\"Order ID\"]\n",
    "        self.product = row[\"Item Type\"]\n",
    "        self.price = row[\"Unit Price\"]\n",
    "        self.quantity = row[\"Units Sold\"]\n",
    "        self.coupon_code = row[\"coupon_code\"]\n",
    "        self.shipping_city = row[\"Country\"]\n",
    "\n",
    "    def clean(self):\n",
    "        # ---------- Clean city ----------\n",
    "        if pd.notnull(self.shipping_city):\n",
    "            self.shipping_city = str(self.shipping_city).strip().lower()\n",
    "        \n",
    "        # ---------- Clean coupon ----------\n",
    "        if pd.notnull(self.coupon_code):\n",
    "            self.coupon_code = str(self.coupon_code).strip().upper()\n",
    "        \n",
    "        \n",
    "        # ---------- Re-parse order date ----------\n",
    "        try:\n",
    "            self.order_date = pd.to_datetime(self.order_date, errors=\"coerce\", dayfirst=True)\n",
    "        except:\n",
    "            self.order_date = pd.NaT\n",
    "\n",
    "# ----------  Load and clean transactions ----------\n",
    "def load_transactions(df):\n",
    "    return [Transaction(row) for index, row in df.iterrows()]\n",
    "\n",
    "transactions = load_transactions(data1)\n",
    "\n",
    "# ---------- Show before cleaning ----------\n",
    "before_cities = len(set(t.shipping_city for t in transactions if pd.notnull(t.shipping_city)))\n",
    "\n",
    "# ---------- Apply cleaning ----------\n",
    "for t in transactions:\n",
    "    t.clean()\n",
    "\n",
    "# ---------- Show after cleaning ----------\n",
    "after_cities = len(set(t.shipping_city for t in transactions if pd.notnull(t.shipping_city)))\n",
    "# ---------- remove any transactions with missing order_date ----------\n",
    "transactions = [t for t in transactions if pd.notnull(t.order_date)]\n",
    "\n",
    "\n",
    "print(\"Cities before cleaning:\", before_cities)\n",
    "print(\"Cities after cleaning:\", after_cities)\n",
    "print(\"Order dates cleaned \")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0d8953b",
   "metadata": {},
   "source": [
    "In this step, I cleaned up two main fields: the country names and the order dates.\n",
    "\n",
    "- For country names, I removed extra spaces and changed them all to lowercase so they are consistent.\n",
    "- For order dates, I used pandas to convert all date formats into one clean datet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34f4002b",
   "metadata": {},
   "source": [
    "#  Step 8: Transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e2df322",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ---------- load the second file that has coupon info ----------\n",
    "coupon_info = pd.read_csv(r\"D:\\Conestoga\\Machine Learning Programming\\Lab-2\\discount.csv\")\n",
    "print(coupon_info.head())\n",
    "\n",
    "# ---------- make a dictionary from it ----------\n",
    "coupon_dict = dict(zip(coupon_info[\"coupon_code\"].str.upper(), coupon_info[\"discount_percent\"]))\n",
    "\n",
    "# ---------- update the clean() method to include discount ----------\n",
    "for t in transactions:\n",
    "    # ---------- make sure code is uppercase ----------\n",
    "    if t.coupon_code:\n",
    "        code = t.coupon_code.upper()\n",
    "        t.discount_percent = coupon_dict.get(code, 0)\n",
    "    else:\n",
    "        t.discount_percent = 0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75d1eb78",
   "metadata": {},
   "source": [
    "\n",
    "In this step, I used the `coupon_code` to add a new field called `discount_percent` and  loaded a second file which had the discounts for each code. Then I matched them using a dictionary.\n",
    "\n",
    "If the code was missing or not in the list, I just used 0 as the discount.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bddbe458",
   "metadata": {},
   "source": [
    "## Step 9: Feature Engineering\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0eeb11c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "\n",
    "# ---------- get today's date ----------\n",
    "today = pd.Timestamp.today()\n",
    "\n",
    "# ---------- calculate days since purchase for each transaction ----------\n",
    "for t in transactions:\n",
    "    if pd.notnull(t.order_date):\n",
    "        diff = today - t.order_date\n",
    "        t.days_since_purchase = diff.days\n",
    "    else:\n",
    "        t.days_since_purchase = None\n",
    "# Print the first 5 transactions with their order date and days_since_purchase\n",
    "sample_data = [\n",
    "    {\n",
    "        \"Order Date\": t.order_date,\n",
    "        \"Days Since Purchase\": t.days_since_purchase\n",
    "    }\n",
    "    for t in transactions[:5]\n",
    "]\n",
    "\n",
    "import pandas as pd\n",
    "pd.DataFrame(sample_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d36fc3ed",
   "metadata": {},
   "source": [
    "\n",
    "Here I added a new column called `days_since_purchase`and used Python to check how many days ago each order happened by subtracting the order date from today’s date.\n",
    "\n",
    "If the order date was missing I just left it empty (None).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3806f45e",
   "metadata": {},
   "source": [
    "## Step 10: Mini Aggregation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c3c1d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ---------- make a dictionary to store city revenue ----------\n",
    "city_revenue = {}\n",
    "\n",
    "for t in transactions:\n",
    "    if t.shipping_city:\n",
    "        revenue = t.price * t.quantity\n",
    "        if t.shipping_city in city_revenue:\n",
    "            city_revenue[t.shipping_city] += revenue\n",
    "        else:\n",
    "            city_revenue[t.shipping_city] = revenue\n",
    "\n",
    "for city, revenue in list(city_revenue.items())[:5]:\n",
    "    print(city, \"=\", round(revenue, 2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "870061fe",
   "metadata": {},
   "source": [
    "I created a small summary that shows how much revenue came from each city.\n",
    "\n",
    "To do this, I used a Python dictionary. I looped through all the transactions and calculated revenue (price × quantity), then added it by city name.\n",
    "\n",
    "This helps us see where the most orders came from.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c76d7a6",
   "metadata": {},
   "source": [
    "##  Step 11: Serialization Checkpoint \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ded3008d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "\n",
    "# ---------- make a list of dictionaries from each Transaction ----------\n",
    "records = []\n",
    "for t in transactions:\n",
    "    records.append({\n",
    "        \"order_date\": t.order_date,\n",
    "        \"customer_id\": t.customer_id,\n",
    "        \"product\": t.product,\n",
    "        \"price\": t.price,\n",
    "        \"quantity\": t.quantity,\n",
    "        \"coupon_code\": t.coupon_code,\n",
    "        \"shipping_city\": t.shipping_city,\n",
    "        \"discount_percent\": getattr(t, \"discount_percent\", 0),\n",
    "        \"days_since_purchase\": getattr(t, \"days_since_purchase\", None)\n",
    "    })\n",
    "\n",
    "# ---------- turn into a DataFrame ----------\n",
    "df_final = pd.DataFrame(records)\n",
    "\n",
    "# ---------- save as JSON ----------\n",
    "df_final.to_json(\"cleaned_data.json\", orient=\"records\", lines=True)\n",
    "\n",
    "# ---------- save as Parquet ----------\n",
    "df_final.to_parquet(\"cleaned_data.parquet\", index=False)\n",
    "\n",
    "print(\" Data saved to JSON and Parquet!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97ffc86f",
   "metadata": {},
   "source": [
    "## Step 11: Saving the Data\n",
    "\n",
    "I saved my final data into two files:\n",
    "\n",
    "- One in JSON format\n",
    "- One in Parquet format\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e77e430c",
   "metadata": {},
   "source": [
    "## Step 12: Reflection – How OOP Helped\n",
    "\n",
    "Objectoriented programming helped me keep my code simple and clean,i  created and used a class called `Transaction` to store each row of data. so i dont have to write code for dataframes everytime so i just call the calss also added a clean() function inside the class inside loop so i clean the data of each transaction simply and faster.\n",
    "it saved time and kept my code organized. If I didn’t use OOP, I think the code would be much longer and harder to manage.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "111a7c15",
   "metadata": {},
   "source": [
    "## Data Dictionary\n",
    "\n",
    "| Field Name           | Type     | Description                        | Source         |\n",
    "|----------------------|----------|------------------------------------|----------------|\n",
    "| order_date           | datetime | Date when order was placed         | sales.csv      |\n",
    "| order_id             | float    | ID of the customer                 | sales.csv      |\n",
    "| product              | string   | Name of the product                | sales.csv      |\n",
    "| price                | float    | Price per unit                     | sales.csv      |\n",
    "| quantity             | integer  | Number of units sold               | sales.csv      |\n",
    "| coupon_code          | string   | Discount code used                 | sales.csv      |\n",
    "| country              | string   | Name of the country (standardized) | sales.csv      |\n",
    "| discount_percent     | integer  | Discount percent from coupon       | discount.csv   |\n",
    "| days_since_purchase  | integer  | Days since order was made          | notebook logic |\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "da1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
