{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d2118eb3",
   "metadata": {},
   "source": [
    "## Step 1: Hello, Data!\n",
    "\n",
    "In this step, I load the raw sales transactions CSV file into a DataFrame and display the first three rows to understand the structure of the data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d00bd3c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   sno                            Region Country   Item Type Sales Channel  \\\n",
      "0    1      middle east and north africa   Libya   Cosmetics       Offline   \n",
      "1    2                     north america  CANADA  Vegetables        Online   \n",
      "2    3    Middle East and North Africa     LIBYA   Baby Food       Offline   \n",
      "\n",
      "  Order Priority  Order Date   Order ID   Ship Date  Units Sold  Unit Price  \\\n",
      "0              M  2014-10-18  686800706  31-10-2014        8446      437.20   \n",
      "1              M  07-11-2011  185941302  2011-12-08        3018      154.06   \n",
      "2              C  2016-10-31  246222341  2016-12-09        1517      255.28   \n",
      "\n",
      "   Unit Cost  Total Revenue  Total Cost  Total Profit coupon_code  \n",
      "0     263.33     3692591.20  2224085.18    1468506.02      GF24TA  \n",
      "1      90.93      464953.08   274426.74     190526.34      10AMSP  \n",
      "2     159.42      387259.76   241840.14     145419.62      TEYPEU  \n"
     ]
    }
   ],
   "source": [
    "# ---------- importing the pandas library ----------\n",
    "import pandas as pd\n",
    "\n",
    "# ---------- reading  CSV file ----------\n",
    "file1 = r\"D:\\Conestoga\\Machine Learning Programming\\Lab-2\\sales_data_with_coupons.csv\"\n",
    "data1 = pd.read_csv(file1)\n",
    "\n",
    "# ---------- displaying the first 3 rows of the data ----------\n",
    "print(data1.head(3))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14e567c5",
   "metadata": {},
   "source": [
    "## Step 2: Pick the Right Container\n",
    "\n",
    "A `dict` is simple but doesnâ€™t group behavior with data and a `namedtuple` is cleaner than a dict,but no custom functions\n",
    "A `class` is best here  because it helps organize the data and lets me add my own methods like `clean()` and `total()`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5df16203",
   "metadata": {},
   "source": [
    "## Step 3: Transaction Class and OO structure \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d0056fd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'order_date': '2014-10-18', 'customer_id': 686800706, 'product': 'Cosmetics', 'price': 437.2, 'quantity': 8446, 'coupon_code': 'GF24TA', 'shipping_city': 'Libya'}\n"
     ]
    }
   ],
   "source": [
    "# ---------- creating a class to represent one transaction ----------\n",
    "\n",
    "class Transaction:\n",
    "    def __init__(self, row):\n",
    "        # ---------- saving each column into the object ----------\n",
    "        self.order_date = row[\"Order Date\"]\n",
    "        self.customer_id = row[\"Order ID\"]\n",
    "        self.product = row[\"Item Type\"]\n",
    "        self.price = row[\"Unit Price\"]\n",
    "        self.quantity = row[\"Units Sold\"]\n",
    "        self.coupon_code = row[\"coupon_code\"]\n",
    "        self.shipping_city = row[\"Country\"] \n",
    "\n",
    "# ---------- creating a list to store all transaction objects ----------\n",
    "transaction_list = []\n",
    "\n",
    "# ---------- going through each row and converting to a Transaction object ----------\n",
    "for index, row in data1.iterrows():\n",
    "    obj = Transaction(row)\n",
    "    transaction_list.append(obj)\n",
    "\n",
    "# ---------- printing the first transaction as a check ----------\n",
    "print(vars(transaction_list[0]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bdf28de",
   "metadata": {},
   "source": [
    "\n",
    "In this step i created a Python class to represent each row in the sales data.\n",
    "I used real column names like \"Order Date\", \"Item Type\", and \"coupon_code\" from the CSV.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e36d6d08",
   "metadata": {},
   "source": [
    "##  Step 4: Bulk Loader \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "91a1f4bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'order_date': '2014-10-18', 'customer_id': 686800706, 'product': 'Cosmetics', 'price': 437.2, 'quantity': 8446, 'coupon_code': 'GF24TA', 'shipping_city': 'Libya'}\n"
     ]
    }
   ],
   "source": [
    "# ---------- importing List for return type hint ----------\n",
    "from typing import List\n",
    "\n",
    "# ---------- function to load all transactions ----------\n",
    "\n",
    "def load_transactions(dataframe) -> List[Transaction]:\n",
    "    # ---------- list to hold transaction objects ----------\n",
    "    result = []\n",
    "\n",
    "    # ---------- loop  each row in the dataframe ----------\n",
    "    for index, row in dataframe.iterrows():\n",
    "        obj = Transaction(row)      # ---------- make Transaction object ----------\n",
    "        result.append(obj)          # ---------- add to list ----------\n",
    "\n",
    "    return result\n",
    "\n",
    "# ---------- using the function to load data ----------\n",
    "transactions = load_transactions(data1)\n",
    "\n",
    "print(vars(transactions[0]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09b975c7",
   "metadata": {},
   "source": [
    "in this step i made a function called `load_transactions()` to turn each row of the data into a `Transaction` object.\n",
    "This function goes through the dataframe row by row and makes a list of all  transactions.\n",
    "It helps to keep the code clean and now i can just call this function anytime I want to load the data as objects.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a1b82de",
   "metadata": {},
   "source": [
    "##  Step 5: Quick Profiling \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "578363bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min price: 9.33\n",
      "Mean price: 274.29506\n",
      "Max price: 668.27\n",
      "Number of unique shipping cities: 360\n"
     ]
    }
   ],
   "source": [
    "# ---------- getting min, mean, and max of unit price ----------\n",
    "\n",
    "min_price = data1[\"Unit Price\"].min()\n",
    "mean_price = data1[\"Unit Price\"].mean()\n",
    "max_price = data1[\"Unit Price\"].max()\n",
    "\n",
    "print(\"Min price:\", min_price)\n",
    "print(\"Mean price:\", mean_price)\n",
    "print(\"Max price:\", max_price)\n",
    "\n",
    "# ---------- getting the number of unique shipping cities ----------\n",
    "unique_cities = data1[\"Country\"].nunique()\n",
    "\n",
    "print(\"Number of unique shipping cities:\", unique_cities)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "273a513e",
   "metadata": {},
   "source": [
    "Here I calculated the minimum, average, and maximum values for the \"Unit Price\" column using the pandas functions `.min()`, `.mean()`, and `.max()`.\n",
    "\n",
    "I also counted how many cities are in the data. It showed 360, but this is wrong.\n",
    "\n",
    "Some city names are written in different ways, like \"canada\" and \"CANADA\", so they are counted more than once.\n",
    "\n",
    "I will fix this in the next step.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "955ef2da",
   "metadata": {},
   "source": [
    "##  Step 6: Spot the Grime  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d370277e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values in each column:\n",
      "sno               0\n",
      "Region            0\n",
      "Country           0\n",
      "Item Type         0\n",
      "Sales Channel     0\n",
      "Order Priority    0\n",
      "Order Date        0\n",
      "Order ID          0\n",
      "Ship Date         0\n",
      "Units Sold        0\n",
      "Unit Price        0\n",
      "Unit Cost         0\n",
      "Total Revenue     0\n",
      "Total Cost        0\n",
      "Total Profit      0\n",
      "coupon_code       0\n",
      "dtype: int64\n",
      "Number of duplicate rows:\n",
      "0\n",
      "Negative Unit Prices:\n",
      "0\n",
      "Zero or negative Units Sold:\n",
      "0\n",
      "Different countries before cleaning:\n",
      "360\n",
      "Different countries after cleaning:\n",
      "171\n",
      "Bad Order Dates: 182\n",
      "Bad Ship Dates: 391\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kittu\\AppData\\Local\\Temp\\ipykernel_20936\\4090554883.py:27: UserWarning: Parsing dates in %Y-%m-%d format when dayfirst=True was specified. Pass `dayfirst=False` or specify a format to silence this warning.\n",
      "  data1[\"Order Date\"] = pd.to_datetime(data1[\"Order Date\"], errors='coerce', dayfirst=True)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ---------- 1. Missing values ----------\n",
    "print(\"Missing values in each column:\")\n",
    "print(data1.isnull().sum())\n",
    "\n",
    "# ---------- 2. Duplicate rows ----------\n",
    "print(\"Number of duplicate rows:\")\n",
    "print(data1.duplicated().sum())\n",
    "\n",
    "# ---------- 3. Negative prices ----------\n",
    "print(\"Negative Unit Prices:\")\n",
    "print((data1[\"Unit Price\"] < 0).sum())\n",
    "\n",
    "# ---------- 4. Zero or negative quantities ----------\n",
    "print(\"Zero or negative Units Sold:\")\n",
    "print((data1[\"Units Sold\"] <= 0).sum())\n",
    "\n",
    "# ---------- 5. Country names not standardized ----------\n",
    "print(\"Different countries before cleaning:\")\n",
    "print(data1[\"Country\"].nunique())\n",
    "\n",
    "# ---------- check how many unique countries after fixing casing + spaces ----------\n",
    "fixed_countries = data1[\"Country\"].str.strip().str.lower()\n",
    "print(\"Different countries after cleaning:\")\n",
    "print(fixed_countries.nunique())\n",
    "\n",
    "# ---------- 6. Fix and check date columns ----------\n",
    "data1[\"Order Date\"] = pd.to_datetime(data1[\"Order Date\"], errors='coerce', dayfirst=True)\n",
    "data1[\"Ship Date\"] = pd.to_datetime(data1[\"Ship Date\"], errors='coerce', dayfirst=True)\n",
    "\n",
    "print(\"Bad Order Dates:\", data1[\"Order Date\"].isna().sum())\n",
    "print(\"Bad Ship Dates:\", data1[\"Ship Date\"].isna().sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab2d2862",
   "metadata": {},
   "source": [
    "country  names have issues  \n",
    "1. they have extra spaces \n",
    "2. different cases. \n",
    "3. Dates were not in the same format I will clean them next.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee9211be",
   "metadata": {},
   "source": [
    "##  Step 7: Cleaning Rules \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e15dfe21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cities before cleaning: 360\n",
      "Cities after cleaning: 171\n",
      "Order dates cleaned \n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ------------------to Convert Order Date -------------------- \n",
    "data1[\"Order Date\"] = pd.to_datetime(data1[\"Order Date\"], errors=\"coerce\", dayfirst=True)\n",
    "\n",
    "# ---------- Step 7B: Transaction class with clean() ----------\n",
    "class Transaction:\n",
    "    def __init__(self, row):\n",
    "        self.order_date = row[\"Order Date\"]\n",
    "        self.customer_id = row[\"Order ID\"]\n",
    "        self.product = row[\"Item Type\"]\n",
    "        self.price = row[\"Unit Price\"]\n",
    "        self.quantity = row[\"Units Sold\"]\n",
    "        self.coupon_code = row[\"coupon_code\"]\n",
    "        self.shipping_city = row[\"Country\"]\n",
    "\n",
    "    def clean(self):\n",
    "        # ---------- Clean city ----------\n",
    "        if pd.notnull(self.shipping_city):\n",
    "            self.shipping_city = str(self.shipping_city).strip().lower()\n",
    "        \n",
    "        # ---------- Clean coupon ----------\n",
    "        if pd.notnull(self.coupon_code):\n",
    "            self.coupon_code = str(self.coupon_code).strip().upper()\n",
    "        \n",
    "        \n",
    "        # ---------- Re-parse order date ----------\n",
    "        try:\n",
    "            self.order_date = pd.to_datetime(self.order_date, errors=\"coerce\", dayfirst=True)\n",
    "        except:\n",
    "            self.order_date = pd.NaT\n",
    "\n",
    "# ---------- Step 7C: Load and clean transactions ----------\n",
    "def load_transactions(df):\n",
    "    return [Transaction(row) for index, row in df.iterrows()]\n",
    "\n",
    "transactions = load_transactions(data1)\n",
    "\n",
    "# ---------- Show before cleaning ----------\n",
    "before_cities = len(set(t.shipping_city for t in transactions if pd.notnull(t.shipping_city)))\n",
    "\n",
    "# ---------- Apply cleaning ----------\n",
    "for t in transactions:\n",
    "    t.clean()\n",
    "\n",
    "# ---------- Show after cleaning ----------\n",
    "after_cities = len(set(t.shipping_city for t in transactions if pd.notnull(t.shipping_city)))\n",
    "\n",
    "# ---------- Output ----------\n",
    "print(\"Cities before cleaning:\", before_cities)\n",
    "print(\"Cities after cleaning:\", after_cities)\n",
    "print(\"Order dates cleaned \")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0d8953b",
   "metadata": {},
   "source": [
    "In this step, I cleaned up two main fields: the country names and the order dates.\n",
    "\n",
    "- For country names, I removed extra spaces and changed them all to lowercase so they are consistent.\n",
    "- For order dates, I used pandas to convert all date formats into one clean datet"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "da1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
